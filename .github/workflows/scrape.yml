name: Weekly scrape

on:
  schedule:
    # Every Monday 00:05 JST => Sunday 15:05 UTC
    - cron: '5 15 * * 0'
  workflow_dispatch: {}   # lets you run it manually from the Actions tab

permissions:
  contents: write         # allow the job to commit data back to the repo

jobs:
  run:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install deps
        run: |
          pip install -r scraper/requirements.txt

      - name: Scrape
        run: |
          python scraper/scrape.py

      - name: Commit data changes if any
        run: |
          if [ -n "$(git status --porcelain data/)" ]; then
            git config user.name "github-actions[bot]"
            git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
            git add data/
            git commit -m "chore(data): weekly refresh $(date -u +'%Y-%m-%dT%H:%MZ')"
            git push
          else
            echo "No changes."
          fi
